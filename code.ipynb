{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\POS_Tagging\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data_module.udpos_dataset import UDPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "udpos = UDPOS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dataset Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of training examples in each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(udpos.train)}\")\n",
    "print(f\"Number of validation examples: {len(udpos.val)}\")\n",
    "print(f\"Number of testing examples: {len(udpos.test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what each example looks like. Here,\n",
    "* The `text` field will be used as feature for the POS tagger model.\n",
    "* The `udtags` field will be used as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " al - zaman : american forces killed shaikh abdullah al - ani , the preacher at the mosque in the town of qaim , near the syrian border .\n",
      "UD Tags\n",
      " ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "example = vars(udpos.train.examples[0])\n",
    "print(\"Text\\n\", ' '.join(example['text']))\n",
    "print(\"UD Tags\\n\", example['udtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2. Analyzing Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields are preprocessed. This means, the tokenization step has been performed. Let's check what the vocabulary size is for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8866\n",
      "Unique tokens in UD_TAG vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(udpos.TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(udpos.UD_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the top 10 most common tokens in `text` are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common tokens in text are as follows:\n",
      " 1) the   has count  9076\n",
      " 2) .     has count  8640\n",
      " 3) ,     has count  7021\n",
      " 4) to    has count  5137\n",
      " 5) and   has count  5002\n",
      " 6) a     has count  3782\n",
      " 7) of    has count  3622\n",
      " 8) i     has count  3379\n",
      " 9) in    has count  3112\n",
      "10) is    has count  2239\n"
     ]
    }
   ],
   "source": [
    "TOP = 10\n",
    "\n",
    "print(f\"Top {TOP} most common tokens in text are as follows:\")\n",
    "\n",
    "for i, (token, count) in enumerate(udpos.TEXT.vocab.freqs.most_common(TOP)):\n",
    "    print(f\"{i+1:>2}) {token:<5} has count {count:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how many distinct POS tags there are in `udtags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 in total which are as follows\n",
      " 1)   NOUN (34781)\n",
      " 2)  PUNCT (23679)\n",
      " 3)   VERB (23081)\n",
      " 4)   PRON (18577)\n",
      " 5)    ADP (17638)\n",
      " 6)    DET (16285)\n",
      " 7)  PROPN (12946)\n",
      " 8)    ADJ (12477)\n",
      " 9)    AUX (12343)\n",
      "10)    ADV (10548)\n",
      "11)  CCONJ (6707)\n",
      "12)   PART (5567)\n",
      "13)    NUM (3999)\n",
      "14)  SCONJ (3843)\n",
      "15)      X (847)\n",
      "16)   INTJ (688)\n",
      "17)    SYM (599)\n"
     ]
    }
   ],
   "source": [
    "unique_pos_tags = len(udpos.UD_TAGS.vocab)\n",
    "\n",
    "print(f\"There are {unique_pos_tags} in total which are as follows\")\n",
    "\n",
    "for i, (tag, count) in enumerate(udpos.UD_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{i+1:>2}) {tag:>6} ({count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Batch Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will use vectorzied computation to be efficient. For that, we need to iterate over the dataset in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = udpos.get_iterators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the iterator looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64 from UDPOS]\n",
      "\t[.text]:[torch.LongTensor of size 65x64]\n",
      "\t[.udtags]:[torch.LongTensor of size 65x64]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch has two fields, `text` and `udtags`. The shape of both the fields is $65 \\times 64$. Here's what this means:\n",
    "\n",
    "* **Number of steps**: 65. Meaning, there are 65 sequential tokens. \n",
    "* **Batches**: 64. Meaning, there are 64 different sequences.\n",
    "\n",
    "Let's look at a breakdown of one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: at weekend press conferences in salt lake city and phoenix , fbi and state officials said jeffs \" is considered armed and dangerous and may be traveling with armed <unk> . \" <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tags: ADP NOUN NOUN NOUN ADP PROPN PROPN PROPN CCONJ PROPN PUNCT PROPN CCONJ NOUN NOUN VERB PROPN PUNCT AUX VERB ADJ CCONJ ADJ CCONJ AUX AUX VERB ADP ADJ NOUN PUNCT PUNCT <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    text, tags = batch.text.T, batch.udtags.T\n",
    "\n",
    "    print(\"Text:\", \" \".join(udpos.TEXT.vocab.itos[i]\n",
    "                            for i in text[0]))\n",
    "    print(\"Tags:\", \" \".join(udpos.UD_TAGS.vocab.itos[i]\n",
    "                            for i in tags[0]))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing the filed values, their shape becomes $64 \\times 65$. So each row is now one example sentence. Thus the sentence makes sense when we print it. In the LSTM model, we'll iterate over timesteps and look at a batch of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\POS_Tagging\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first specify some hyperparameter values. These will dictate the architectural constraints of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Base LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.module.lstm import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(num_inputs=EMBEDDING_DIM, num_hiddens=HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of parameters making up the LSTM model\n",
      "W_xf  with shape torch.Size([100, 128])\n",
      "W_hf  with shape torch.Size([128, 128])\n",
      "b_f   with shape torch.Size([128])\n",
      "W_xi  with shape torch.Size([100, 128])\n",
      "W_hi  with shape torch.Size([128, 128])\n",
      "b_i   with shape torch.Size([128])\n",
      "W_xo  with shape torch.Size([100, 128])\n",
      "W_ho  with shape torch.Size([128, 128])\n",
      "b_o   with shape torch.Size([128])\n",
      "W_xc  with shape torch.Size([100, 128])\n",
      "W_hc  with shape torch.Size([128, 128])\n",
      "b_c   with shape torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(\"List of parameters making up the LSTM model\")\n",
    "\n",
    "for name, params in lstm.named_parameters():\n",
    "    print(f\"{name:<5} with shape {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = torch.randn((65, BATCH_SIZE, EMBEDDING_DIM))\n",
    "outputs, (H, C) = lstm(dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 65\n",
      "Shape of Hidden State: torch.Size([64, 128])\n",
      "Shape of Memory Cell State: torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of outputs:\", len(outputs))\n",
    "print(\"Shape of Hidden State:\", H.shape)\n",
    "print(\"Shape of Memory Cell State:\", C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output dimensions match expected values. So our implementation is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.module.bi_lstm import BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm = BiLSTM(num_inputs=EMBEDDING_DIM, num_hiddens=HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of parameters making up the LSTM model\n",
      "forward_lstm.W_xf    with shape torch.Size([100, 128])\n",
      "forward_lstm.W_hf    with shape torch.Size([128, 128])\n",
      "forward_lstm.b_f     with shape torch.Size([128])\n",
      "forward_lstm.W_xi    with shape torch.Size([100, 128])\n",
      "forward_lstm.W_hi    with shape torch.Size([128, 128])\n",
      "forward_lstm.b_i     with shape torch.Size([128])\n",
      "forward_lstm.W_xo    with shape torch.Size([100, 128])\n",
      "forward_lstm.W_ho    with shape torch.Size([128, 128])\n",
      "forward_lstm.b_o     with shape torch.Size([128])\n",
      "forward_lstm.W_xc    with shape torch.Size([100, 128])\n",
      "forward_lstm.W_hc    with shape torch.Size([128, 128])\n",
      "forward_lstm.b_c     with shape torch.Size([128])\n",
      "backward_lstm.W_xf   with shape torch.Size([100, 128])\n",
      "backward_lstm.W_hf   with shape torch.Size([128, 128])\n",
      "backward_lstm.b_f    with shape torch.Size([128])\n",
      "backward_lstm.W_xi   with shape torch.Size([100, 128])\n",
      "backward_lstm.W_hi   with shape torch.Size([128, 128])\n",
      "backward_lstm.b_i    with shape torch.Size([128])\n",
      "backward_lstm.W_xo   with shape torch.Size([100, 128])\n",
      "backward_lstm.W_ho   with shape torch.Size([128, 128])\n",
      "backward_lstm.b_o    with shape torch.Size([128])\n",
      "backward_lstm.W_xc   with shape torch.Size([100, 128])\n",
      "backward_lstm.W_hc   with shape torch.Size([128, 128])\n",
      "backward_lstm.b_c    with shape torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(\"List of parameters making up the LSTM model\")\n",
    "\n",
    "for name, params in bi_lstm.named_parameters():\n",
    "    print(f\"{name:<20} with shape {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = torch.randn((65, BATCH_SIZE, EMBEDDING_DIM))\n",
    "outputs, (f_h, b_h) = bi_lstm(dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 65\n",
      "Shape of Forward Hidden State: torch.Size([64, 128])\n",
      "Shape of Forward Memory Cell: torch.Size([64, 128])\n",
      "Shape of backward Hidden State: torch.Size([64, 128])\n",
      "Shape of backward Memory Cell: torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of outputs:\", len(outputs))\n",
    "print(\"Shape of Forward Hidden State:\", f_h[0].shape)\n",
    "print(\"Shape of Forward Memory Cell:\", f_h[1].shape)\n",
    "print(\"Shape of backward Hidden State:\", b_h[0].shape)\n",
    "print(\"Shape of backward Memory Cell:\", b_h[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
