{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\POS_Tagging\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data_module.udpos_dataset import UDPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "udpos = UDPOS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dataset Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of training examples in each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(udpos.train)}\")\n",
    "print(f\"Number of validation examples: {len(udpos.val)}\")\n",
    "print(f\"Number of testing examples: {len(udpos.test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what each example looks like. Here,\n",
    "* The `text` field will be used as feature for the POS tagger model.\n",
    "* The `udtags` field will be used as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " al - zaman : american forces killed shaikh abdullah al - ani , the preacher at the mosque in the town of qaim , near the syrian border .\n",
      "UD Tags\n",
      " ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "example = vars(udpos.train.examples[0])\n",
    "print(\"Text\\n\", ' '.join(example['text']))\n",
    "print(\"UD Tags\\n\", example['udtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2. Analyzing Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields are preprocessed. This means, the tokenization step has been performed. Let's check what the vocabulary size is for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8866\n",
      "Unique tokens in UD_TAG vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(udpos.TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(udpos.UD_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the top 10 most common tokens in `text` are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common tokens in text are as follows:\n",
      " 1) the   has count  9076\n",
      " 2) .     has count  8640\n",
      " 3) ,     has count  7021\n",
      " 4) to    has count  5137\n",
      " 5) and   has count  5002\n",
      " 6) a     has count  3782\n",
      " 7) of    has count  3622\n",
      " 8) i     has count  3379\n",
      " 9) in    has count  3112\n",
      "10) is    has count  2239\n"
     ]
    }
   ],
   "source": [
    "TOP = 10\n",
    "\n",
    "print(f\"Top {TOP} most common tokens in text are as follows:\")\n",
    "\n",
    "for i, (token, count) in enumerate(udpos.TEXT.vocab.freqs.most_common(TOP)):\n",
    "    print(f\"{i+1:>2}) {token:<5} has count {count:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how many distinct POS tags there are in `udtags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 in total which are as follows\n",
      " 1)   NOUN (34781)\n",
      " 2)  PUNCT (23679)\n",
      " 3)   VERB (23081)\n",
      " 4)   PRON (18577)\n",
      " 5)    ADP (17638)\n",
      " 6)    DET (16285)\n",
      " 7)  PROPN (12946)\n",
      " 8)    ADJ (12477)\n",
      " 9)    AUX (12343)\n",
      "10)    ADV (10548)\n",
      "11)  CCONJ (6707)\n",
      "12)   PART (5567)\n",
      "13)    NUM (3999)\n",
      "14)  SCONJ (3843)\n",
      "15)      X (847)\n",
      "16)   INTJ (688)\n",
      "17)    SYM (599)\n"
     ]
    }
   ],
   "source": [
    "unique_pos_tags = len(udpos.UD_TAGS.vocab)\n",
    "\n",
    "print(f\"There are {unique_pos_tags} in total which are as follows\")\n",
    "\n",
    "for i, (tag, count) in enumerate(udpos.UD_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{i+1:>2}) {tag:>6} ({count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Batch Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will use vectorzied computation to be efficient. For that, we need to iterate over the dataset in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = udpos.get_iterators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the iterator looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64 from UDPOS]\n",
      "\t[.text]:[torch.LongTensor of size 65x64]\n",
      "\t[.udtags]:[torch.LongTensor of size 65x64]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch has two fields, `text` and `udtags`. The shape of both the fields is $65 \\times 64$. Here's what this means:\n",
    "\n",
    "* **Number of steps**: 65. Meaning, there are 65 sequential tokens. \n",
    "* **Batches**: 64. Meaning, there are 64 different sequences.\n",
    "\n",
    "Let's look at a breakdown of one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: at weekend press conferences in salt lake city and phoenix , fbi and state officials said jeffs \" is considered armed and dangerous and may be traveling with armed <unk> . \" <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tags: ADP NOUN NOUN NOUN ADP PROPN PROPN PROPN CCONJ PROPN PUNCT PROPN CCONJ NOUN NOUN VERB PROPN PUNCT AUX VERB ADJ CCONJ ADJ CCONJ AUX AUX VERB ADP ADJ NOUN PUNCT PUNCT <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    text, tags = batch.text.T, batch.udtags.T\n",
    "\n",
    "    print(\"Text:\", \" \".join(udpos.TEXT.vocab.itos[i]\n",
    "                            for i in text[0]))\n",
    "    print(\"Tags:\", \" \".join(udpos.UD_TAGS.vocab.itos[i]\n",
    "                            for i in tags[0]))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing the filed values, their shape becomes $64 \\times 65$. So each row is now one example sentence. Thus the sentence makes sense when we print it. In the LSTM model, we'll iterate over timesteps and look at a batch of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
