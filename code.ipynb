{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\POS_Tagging\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data_module.udpos_dataset import UDPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading en-ud-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\udpos\\en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 1.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [10:35, 1.36MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:22<00:00, 17564.07it/s]\n"
     ]
    }
   ],
   "source": [
    "udpos = UDPOS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of training examples in each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(udpos.train)}\")\n",
    "print(f\"Number of validation examples: {len(udpos.val)}\")\n",
    "print(f\"Number of testing examples: {len(udpos.test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what each example looks like. Here,\n",
    "* The `text` field will be used as feature for the POS tagger model.\n",
    "* The `udtags` field will be used as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " al - zaman : american forces killed shaikh abdullah al - ani , the preacher at the mosque in the town of qaim , near the syrian border .\n",
      "UD Tags\n",
      " ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "example = vars(udpos.train.examples[0])\n",
    "print(\"Text\\n\", ' '.join(example['text']))\n",
    "print(\"UD Tags\\n\", example['udtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields are preprocessed. This means, the tokenization step has been performed. Let's check what the vocabulary size is for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8866\n",
      "Unique tokens in UD_TAG vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(udpos.TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(udpos.UD_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the top 10 most common tokens in `text` are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common tokens in text are as follows:\n",
      " 1) the   has count  9076\n",
      " 2) .     has count  8640\n",
      " 3) ,     has count  7021\n",
      " 4) to    has count  5137\n",
      " 5) and   has count  5002\n",
      " 6) a     has count  3782\n",
      " 7) of    has count  3622\n",
      " 8) i     has count  3379\n",
      " 9) in    has count  3112\n",
      "10) is    has count  2239\n"
     ]
    }
   ],
   "source": [
    "TOP = 10\n",
    "\n",
    "print(f\"Top {TOP} most common tokens in text are as follows:\")\n",
    "\n",
    "for i, (token, count) in enumerate(udpos.TEXT.vocab.freqs.most_common(TOP)):\n",
    "    print(f\"{i+1:>2}) {token:<5} has count {count:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
